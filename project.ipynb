{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of emails into spam and ham\n",
    "In this project we have a dataset containing different emails and we have to classify them into spam and ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron,SGDClassifier,PassiveAggressiveClassifier\n",
    "from sklearn.metrics import precision_score,recall_score, f1_score, accuracy_score\n",
    "\n",
    "#pre-settings \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets =pd.read_csv('ham-spam/spamhamdata.csv',sep='\\t',header=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type                                              Email\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_datasets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type                   Email\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_datasets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Type    5572 non-null   object\n",
      " 1   Email   5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "imported_datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "punctuations=string.punctuation\n",
    "stop_words=stopwords.words('english')\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations=string.punctuation\n",
    "stop_words=stopwords.words('english')\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "#convert spam and ham to 0/1\n",
    "#remove stop words\n",
    "    # tokenize the text\n",
    "    # convert text to lowercase\n",
    "    # remove punctuation\n",
    "    # remove numerical values\n",
    "    # stem or lemmatize the words\n",
    "    # return the cleaned text\n",
    "def preprocess(obj):\n",
    "    words = word_tokenize(obj)\n",
    "    corpus=[word.lower() for word in words if word not in stop_words and word not in punctuations]\n",
    "    corpus=[lemmatizer.lemmatize(words) for words in corpus]\n",
    "    corpus=' '.join(corpus)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets['Email']=imported_datasets['Email'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets['IsSpam']=imported_datasets['Type'].apply(lambda x:1 if x=='spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets=imported_datasets.drop('Type',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>IsSpam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy .. available bugis n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar ... joking wif u oni ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Email  IsSpam\n",
       "0  go jurong point crazy .. available bugis n gre...       0\n",
       "1                    ok lar ... joking wif u oni ...       0\n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_datasets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorzation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8186\n",
      "['00' '000' '000pes' ... 'èn' 'ú1' '〨ud']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer=CountVectorizer()\n",
    "tfidf=TfidfVectorizer()\n",
    "Emails=imported_datasets['Email']\n",
    "Emails_tfidf=tfidf.fit_transform(Emails)\n",
    "Emails_count_vectorizer=count_vectorizer.fit_transform(Emails)\n",
    "print(len(tfidf.get_feature_names_out()))\n",
    "print(count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emails_tfidf[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of data and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Emails_tfidf\n",
    "y=imported_datasets['IsSpam']\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.linear_model import Perceptron,SGDClassifier,PassiveAggressiveClassifier\n",
    "\n",
    "#ensemble\n",
    "bagging=BaggingClassifier()\n",
    "ada=AdaBoostClassifier()\n",
    "extra_trees=ExtraTreesClassifier()\n",
    "gradient=GradientBoostingClassifier()\n",
    "random_forest=RandomForestClassifier()\n",
    "\n",
    "#naive bayes\n",
    "multinomial=MultinomialNB()\n",
    "bernoulli=BernoulliNB()\n",
    "\n",
    "#neural network\n",
    "mlp=MLPClassifier()\n",
    "\n",
    "#linear model\n",
    "perceptron=Perceptron()\n",
    "sgd=SGDClassifier()\n",
    "passive_aggressive=PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs={\n",
    "    'Bagging':bagging,\n",
    "    'AdaBoost':ada,\n",
    "    'ExtraTrees':extra_trees,\n",
    "    'GradientBoosting':gradient,\n",
    "    'RandomForest':random_forest,\n",
    "    'MultinomialNB':multinomial,\n",
    "    'BernoulliNB':bernoulli,\n",
    "    'MLP':mlp,\n",
    "    'Perceptron':perceptron,\n",
    "    'SGD':sgd,\n",
    "    'PassiveAggressiveClassifier':passive_aggressive\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging trained\n",
      "Bagging accuracy: 0.97847533632287\n",
      "Bagging precision: 0.9699248120300752\n",
      "Bagging recall: 0.8657718120805369\n",
      "Bagging f1-score: 0.9148936170212766\n",
      "Bagging confusion matrix: \n",
      "[[962   4]\n",
      " [ 20 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDEs\\anaconda\\envs\\email-ham-spam\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost trained\n",
      "AdaBoost accuracy: 0.9811659192825112\n",
      "AdaBoost precision: 0.9507042253521126\n",
      "AdaBoost recall: 0.9060402684563759\n",
      "AdaBoost f1-score: 0.9278350515463918\n",
      "AdaBoost confusion matrix: \n",
      "[[959   7]\n",
      " [ 14 135]]\n",
      "ExtraTrees trained\n",
      "ExtraTrees accuracy: 0.9820627802690582\n",
      "ExtraTrees precision: 0.9849624060150376\n",
      "ExtraTrees recall: 0.8791946308724832\n",
      "ExtraTrees f1-score: 0.9290780141843972\n",
      "ExtraTrees confusion matrix: \n",
      "[[964   2]\n",
      " [ 18 131]]\n",
      "GradientBoosting trained\n",
      "GradientBoosting accuracy: 0.9775784753363229\n",
      "GradientBoosting precision: 0.984375\n",
      "GradientBoosting recall: 0.8456375838926175\n",
      "GradientBoosting f1-score: 0.9097472924187726\n",
      "GradientBoosting confusion matrix: \n",
      "[[964   2]\n",
      " [ 23 126]]\n",
      "RandomForest trained\n",
      "RandomForest accuracy: 0.9811659192825112\n",
      "RandomForest precision: 1.0\n",
      "RandomForest recall: 0.8590604026845637\n",
      "RandomForest f1-score: 0.924187725631769\n",
      "RandomForest confusion matrix: \n",
      "[[966   0]\n",
      " [ 21 128]]\n",
      "MultinomialNB trained\n",
      "MultinomialNB accuracy: 0.9739910313901345\n",
      "MultinomialNB precision: 1.0\n",
      "MultinomialNB recall: 0.8053691275167785\n",
      "MultinomialNB f1-score: 0.8921933085501859\n",
      "MultinomialNB confusion matrix: \n",
      "[[966   0]\n",
      " [ 29 120]]\n",
      "BernoulliNB trained\n",
      "BernoulliNB accuracy: 0.9811659192825112\n",
      "BernoulliNB precision: 0.9637681159420289\n",
      "BernoulliNB recall: 0.8926174496644296\n",
      "BernoulliNB f1-score: 0.926829268292683\n",
      "BernoulliNB confusion matrix: \n",
      "[[961   5]\n",
      " [ 16 133]]\n",
      "MLP trained\n",
      "MLP accuracy: 0.9874439461883409\n",
      "MLP precision: 0.9927007299270073\n",
      "MLP recall: 0.912751677852349\n",
      "MLP f1-score: 0.951048951048951\n",
      "MLP confusion matrix: \n",
      "[[965   1]\n",
      " [ 13 136]]\n",
      "Perceptron trained\n",
      "Perceptron accuracy: 0.97847533632287\n",
      "Perceptron precision: 0.9139072847682119\n",
      "Perceptron recall: 0.9261744966442953\n",
      "Perceptron f1-score: 0.92\n",
      "Perceptron confusion matrix: \n",
      "[[953  13]\n",
      " [ 11 138]]\n",
      "SGD trained\n",
      "SGD accuracy: 0.9874439461883409\n",
      "SGD precision: 1.0\n",
      "SGD recall: 0.9060402684563759\n",
      "SGD f1-score: 0.9507042253521126\n",
      "SGD confusion matrix: \n",
      "[[966   0]\n",
      " [ 14 135]]\n",
      "PassiveAggressiveClassifier trained\n",
      "PassiveAggressiveClassifier accuracy: 0.9856502242152466\n",
      "PassiveAggressiveClassifier precision: 0.9784172661870504\n",
      "PassiveAggressiveClassifier recall: 0.912751677852349\n",
      "PassiveAggressiveClassifier f1-score: 0.9444444444444444\n",
      "PassiveAggressiveClassifier confusion matrix: \n",
      "[[963   3]\n",
      " [ 13 136]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    print(f'{name} trained')\n",
    "    ypred=clf.predict(xtest)\n",
    "    print(f'{name} accuracy: {sklearn.metrics.accuracy_score(ytest,ypred)}')\n",
    "    print(f'{name} precision: {precision_score(ytest,ypred)}')\n",
    "    print(f'{name} recall: {recall_score(ytest,ypred)}')\n",
    "    print(f'{name} f1-score: {f1_score(ytest,ypred)}')\n",
    "    print(f'{name} confusion matrix: ')\n",
    "    print(sklearn.metrics.confusion_matrix(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=len(count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093\n"
     ]
    }
   ],
   "source": [
    "nEstimators=int(features*0.5)\n",
    "print(nEstimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble\n",
    "bagging=BaggingClassifier(n_estimators=nEstimators)\n",
    "ada=AdaBoostClassifier(n_estimators=nEstimators)\n",
    "extra_trees=ExtraTreesClassifier(n_estimators=nEstimators)\n",
    "gradient=GradientBoostingClassifier(n_estimators=nEstimators)\n",
    "random_forest=RandomForestClassifier(n_estimators=nEstimators)\n",
    "\n",
    "#naive bayes\n",
    "multinomial=MultinomialNB()\n",
    "bernoulli=BernoulliNB()\n",
    "\n",
    "#neural network\n",
    "mlp=MLPClassifier(learning_rate='adaptive',verbose=True)\n",
    "\n",
    "#linear model\n",
    "perceptron=Perceptron()\n",
    "sgd=SGDClassifier()\n",
    "passive_aggressive=PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging trained\n",
      "Bagging accuracy: 0.9757847533632287\n",
      "Bagging precision: 0.9420289855072463\n",
      "Bagging recall: 0.87248322147651\n",
      "Bagging f1-score: 0.9059233449477352\n",
      "Bagging confusion matrix: \n",
      "[[958   8]\n",
      " [ 19 130]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDEs\\anaconda\\envs\\email-ham-spam\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost trained\n",
      "AdaBoost accuracy: 0.9811659192825112\n",
      "AdaBoost precision: 0.9507042253521126\n",
      "AdaBoost recall: 0.9060402684563759\n",
      "AdaBoost f1-score: 0.9278350515463918\n",
      "AdaBoost confusion matrix: \n",
      "[[959   7]\n",
      " [ 14 135]]\n",
      "ExtraTrees trained\n",
      "ExtraTrees accuracy: 0.9838565022421525\n",
      "ExtraTrees precision: 1.0\n",
      "ExtraTrees recall: 0.8791946308724832\n",
      "ExtraTrees f1-score: 0.9357142857142857\n",
      "ExtraTrees confusion matrix: \n",
      "[[966   0]\n",
      " [ 18 131]]\n",
      "GradientBoosting trained\n",
      "GradientBoosting accuracy: 0.9766816143497757\n",
      "GradientBoosting precision: 0.984251968503937\n",
      "GradientBoosting recall: 0.8389261744966443\n",
      "GradientBoosting f1-score: 0.9057971014492754\n",
      "GradientBoosting confusion matrix: \n",
      "[[964   2]\n",
      " [ 24 125]]\n",
      "RandomForest trained\n",
      "RandomForest accuracy: 0.9802690582959641\n",
      "RandomForest precision: 1.0\n",
      "RandomForest recall: 0.8523489932885906\n",
      "RandomForest f1-score: 0.9202898550724637\n",
      "RandomForest confusion matrix: \n",
      "[[966   0]\n",
      " [ 22 127]]\n",
      "MultinomialNB trained\n",
      "MultinomialNB accuracy: 0.9739910313901345\n",
      "MultinomialNB precision: 1.0\n",
      "MultinomialNB recall: 0.8053691275167785\n",
      "MultinomialNB f1-score: 0.8921933085501859\n",
      "MultinomialNB confusion matrix: \n",
      "[[966   0]\n",
      " [ 29 120]]\n",
      "BernoulliNB trained\n",
      "BernoulliNB accuracy: 0.9811659192825112\n",
      "BernoulliNB precision: 0.9637681159420289\n",
      "BernoulliNB recall: 0.8926174496644296\n",
      "BernoulliNB f1-score: 0.926829268292683\n",
      "BernoulliNB confusion matrix: \n",
      "[[961   5]\n",
      " [ 16 133]]\n",
      "MLP trained\n",
      "MLP accuracy: 0.9865470852017937\n",
      "MLP precision: 0.9926470588235294\n",
      "MLP recall: 0.9060402684563759\n",
      "MLP f1-score: 0.9473684210526315\n",
      "MLP confusion matrix: \n",
      "[[965   1]\n",
      " [ 14 135]]\n",
      "Perceptron trained\n",
      "Perceptron accuracy: 0.97847533632287\n",
      "Perceptron precision: 0.9139072847682119\n",
      "Perceptron recall: 0.9261744966442953\n",
      "Perceptron f1-score: 0.92\n",
      "Perceptron confusion matrix: \n",
      "[[953  13]\n",
      " [ 11 138]]\n",
      "SGD trained\n",
      "SGD accuracy: 0.9865470852017937\n",
      "SGD precision: 1.0\n",
      "SGD recall: 0.8993288590604027\n",
      "SGD f1-score: 0.9469964664310954\n",
      "SGD confusion matrix: \n",
      "[[966   0]\n",
      " [ 15 134]]\n",
      "PassiveAggressiveClassifier trained\n",
      "PassiveAggressiveClassifier accuracy: 0.9874439461883409\n",
      "PassiveAggressiveClassifier precision: 0.9787234042553191\n",
      "PassiveAggressiveClassifier recall: 0.9261744966442953\n",
      "PassiveAggressiveClassifier f1-score: 0.9517241379310345\n",
      "PassiveAggressiveClassifier confusion matrix: \n",
      "[[963   3]\n",
      " [ 11 138]]\n"
     ]
    }
   ],
   "source": [
    "for name,clf in clfs.items():\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    print(f'{name} trained')\n",
    "    ypred=clf.predict(xtest)\n",
    "    print(f'{name} accuracy: {sklearn.metrics.accuracy_score(ytest,ypred)}')\n",
    "    print(f'{name} precision: {precision_score(ytest,ypred)}')\n",
    "    print(f'{name} recall: {recall_score(ytest,ypred)}')\n",
    "    print(f'{name} f1-score: {f1_score(ytest,ypred)}')\n",
    "    print(f'{name} confusion matrix: ')\n",
    "    print(sklearn.metrics.confusion_matrix(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting model\n",
    "We can see that SGDClassifier is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model=pickle.dump(mlp,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This MLPClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m loaded_model\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\IDEs\\anaconda\\envs\\email-ham-spam\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1158\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \n\u001b[0;32m   1148\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1158\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[1;32md:\\IDEs\\anaconda\\envs\\email-ham-spam\\Lib\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MLPClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "loaded_model=pickle.load(open('model.pkl','rb'))\n",
    "loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain\n",
    "mlp = SGDClassifier()\n",
    "sgd.fit(xtrain, ytrain)\n",
    "\n",
    "# Save\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(sgd, file)\n",
    "\n",
    "# Load and predict\n",
    "loaded_model = pickle.load(open('model.pkl', 'rb'))\n",
    "    \n",
    "predictions = loaded_model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf,open('tfidf.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email-ham-spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
