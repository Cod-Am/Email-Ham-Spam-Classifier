{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of emails into spam and ham\n",
    "In this project we have a dataset containing different emails and we have to classify them into spam and ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron,SGDClassifier,PassiveAggressiveClassifier\n",
    "from sklearn.metrics import precision_score,recall_score, f1_score, accuracy_score\n",
    "\n",
    "#pre-settings \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets =pd.read_csv('ham-spam/spamhamdata.csv',sep='\\t',header=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type                                              Email\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_datasets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type                   Email\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_datasets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Type    5572 non-null   object\n",
      " 1   Email   5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "imported_datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "punctuations=string.punctuation\n",
    "stop_words=stopwords.words('english')\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations=string.punctuation\n",
    "stop_words=stopwords.words('english')\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "#convert spam and ham to 0/1\n",
    "#remove stop words\n",
    "    # tokenize the text\n",
    "    # convert text to lowercase\n",
    "    # remove punctuation\n",
    "    # remove numerical values\n",
    "    # stem or lemmatize the words\n",
    "    # return the cleaned text\n",
    "def preprocess(obj):\n",
    "    words = word_tokenize(obj)\n",
    "    corpus=[word.lower() for word in words if word not in stop_words and word not in punctuations]\n",
    "    corpus=[lemmatizer.lemmatize(words) for words in corpus]\n",
    "    corpus=' '.join(corpus)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets['Email']=imported_datasets['Email'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets['IsSpam']=imported_datasets['Type'].apply(lambda x:1 if x=='spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_datasets=imported_datasets.drop('Type',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>IsSpam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy .. available bugis n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar ... joking wif u oni ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Email  IsSpam\n",
       "0  go jurong point crazy .. available bugis n gre...       0\n",
       "1                    ok lar ... joking wif u oni ...       0\n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...       1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_datasets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorzation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '000pes' ... 'èn' 'ú1' '〨ud']\n",
      "['00' '000' '000pes' ... 'èn' 'ú1' '〨ud']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer=CountVectorizer()\n",
    "tfidf=TfidfVectorizer()\n",
    "Emails=imported_datasets['Email']\n",
    "Emails_tfidf=tfidf.fit_transform(Emails)\n",
    "Emails_count_vectorizer=count_vectorizer.fit_transform(Emails)\n",
    "print(tfidf.get_feature_names_out())\n",
    "print(count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emails_tfidf[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of data and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Emails_tfidf\n",
    "y=imported_datasets['IsSpam']\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.linear_model import Perceptron,SGDClassifier,PassiveAggressiveClassifier\n",
    "\n",
    "#ensemble\n",
    "bagging=BaggingClassifier()\n",
    "ada=AdaBoostClassifier()\n",
    "extra_trees=ExtraTreesClassifier()\n",
    "gradient=GradientBoostingClassifier()\n",
    "random_forest=RandomForestClassifier()\n",
    "\n",
    "#naive bayes\n",
    "multinomial=MultinomialNB()\n",
    "bernoulli=BernoulliNB()\n",
    "\n",
    "#neural network\n",
    "mlp=MLPClassifier()\n",
    "\n",
    "#linear model\n",
    "perceptron=Perceptron()\n",
    "sgd=SGDClassifier()\n",
    "passive_aggressive=PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs={\n",
    "    'Bagging':bagging,\n",
    "    'AdaBoost':ada,\n",
    "    'ExtraTrees':extra_trees,\n",
    "    'GradientBoosting':gradient,\n",
    "    'RandomForest':random_forest,\n",
    "    'MultinomialNB':multinomial,\n",
    "    'BernoulliNB':bernoulli,\n",
    "    'MLP':mlp,\n",
    "    'Perceptron':perceptron,\n",
    "    'SGD':sgd,\n",
    "    'PassiveAggressiveClassifier':passive_aggressive\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging trained\n",
      "Bagging accuracy: 0.9739910313901345\n",
      "Bagging precision: 0.96875\n",
      "Bagging recall: 0.8322147651006712\n",
      "Bagging f1-score: 0.8953068592057761\n",
      "Bagging confusion matrix: \n",
      "[[962   4]\n",
      " [ 25 124]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDEs\\anaconda\\envs\\email-ham-spam\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost trained\n",
      "AdaBoost accuracy: 0.9811659192825112\n",
      "AdaBoost precision: 0.9507042253521126\n",
      "AdaBoost recall: 0.9060402684563759\n",
      "AdaBoost f1-score: 0.9278350515463918\n",
      "AdaBoost confusion matrix: \n",
      "[[959   7]\n",
      " [ 14 135]]\n",
      "ExtraTrees trained\n",
      "ExtraTrees accuracy: 0.9802690582959641\n",
      "ExtraTrees precision: 1.0\n",
      "ExtraTrees recall: 0.8523489932885906\n",
      "ExtraTrees f1-score: 0.9202898550724637\n",
      "ExtraTrees confusion matrix: \n",
      "[[966   0]\n",
      " [ 22 127]]\n",
      "GradientBoosting trained\n",
      "GradientBoosting accuracy: 0.9766816143497757\n",
      "GradientBoosting precision: 0.984251968503937\n",
      "GradientBoosting recall: 0.8389261744966443\n",
      "GradientBoosting f1-score: 0.9057971014492754\n",
      "GradientBoosting confusion matrix: \n",
      "[[964   2]\n",
      " [ 24 125]]\n",
      "RandomForest trained\n",
      "RandomForest accuracy: 0.9838565022421525\n",
      "RandomForest precision: 1.0\n",
      "RandomForest recall: 0.8791946308724832\n",
      "RandomForest f1-score: 0.9357142857142857\n",
      "RandomForest confusion matrix: \n",
      "[[966   0]\n",
      " [ 18 131]]\n",
      "MultinomialNB trained\n",
      "MultinomialNB accuracy: 0.9739910313901345\n",
      "MultinomialNB precision: 1.0\n",
      "MultinomialNB recall: 0.8053691275167785\n",
      "MultinomialNB f1-score: 0.8921933085501859\n",
      "MultinomialNB confusion matrix: \n",
      "[[966   0]\n",
      " [ 29 120]]\n",
      "BernoulliNB trained\n",
      "BernoulliNB accuracy: 0.9811659192825112\n",
      "BernoulliNB precision: 0.9637681159420289\n",
      "BernoulliNB recall: 0.8926174496644296\n",
      "BernoulliNB f1-score: 0.926829268292683\n",
      "BernoulliNB confusion matrix: \n",
      "[[961   5]\n",
      " [ 16 133]]\n",
      "MLP trained\n",
      "MLP accuracy: 0.9865470852017937\n",
      "MLP precision: 0.9926470588235294\n",
      "MLP recall: 0.9060402684563759\n",
      "MLP f1-score: 0.9473684210526315\n",
      "MLP confusion matrix: \n",
      "[[965   1]\n",
      " [ 14 135]]\n",
      "Perceptron trained\n",
      "Perceptron accuracy: 0.97847533632287\n",
      "Perceptron precision: 0.9139072847682119\n",
      "Perceptron recall: 0.9261744966442953\n",
      "Perceptron f1-score: 0.92\n",
      "Perceptron confusion matrix: \n",
      "[[953  13]\n",
      " [ 11 138]]\n",
      "SGD trained\n",
      "SGD accuracy: 0.9865470852017937\n",
      "SGD precision: 1.0\n",
      "SGD recall: 0.8993288590604027\n",
      "SGD f1-score: 0.9469964664310954\n",
      "SGD confusion matrix: \n",
      "[[966   0]\n",
      " [ 15 134]]\n",
      "PassiveAggressiveClassifier trained\n",
      "PassiveAggressiveClassifier accuracy: 0.9865470852017937\n",
      "PassiveAggressiveClassifier precision: 0.9855072463768116\n",
      "PassiveAggressiveClassifier recall: 0.912751677852349\n",
      "PassiveAggressiveClassifier f1-score: 0.9477351916376306\n",
      "PassiveAggressiveClassifier confusion matrix: \n",
      "[[964   2]\n",
      " [ 13 136]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    print(f'{name} trained')\n",
    "    ypred=clf.predict(xtest)\n",
    "    print(f'{name} accuracy: {sklearn.metrics.accuracy_score(ytest,ypred)}')\n",
    "    print(f'{name} precision: {precision_score(ytest,ypred)}')\n",
    "    print(f'{name} recall: {recall_score(ytest,ypred)}')\n",
    "    print(f'{name} f1-score: {f1_score(ytest,ypred)}')\n",
    "    print(f'{name} confusion matrix: ')\n",
    "    print(sklearn.metrics.confusion_matrix(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=len(count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093\n"
     ]
    }
   ],
   "source": [
    "nEstimators=int(features*0.5)\n",
    "print(nEstimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble\n",
    "bagging=BaggingClassifier(n_estimators=nEstimators)\n",
    "ada=AdaBoostClassifier(n_estimators=nEstimators)\n",
    "extra_trees=ExtraTreesClassifier(n_estimators=nEstimators)\n",
    "gradient=GradientBoostingClassifier(n_estimators=nEstimators)\n",
    "random_forest=RandomForestClassifier(n_estimators=nEstimators)\n",
    "\n",
    "#naive bayes\n",
    "multinomial=MultinomialNB()\n",
    "bernoulli=BernoulliNB()\n",
    "\n",
    "#neural network\n",
    "mlp=MLPClassifier(learning_rate='adaptive',verbose=True)\n",
    "\n",
    "#linear model\n",
    "perceptron=Perceptron()\n",
    "sgd=SGDClassifier()\n",
    "passive_aggressive=PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging trained\n",
      "Bagging accuracy: 0.9766816143497757\n",
      "Bagging precision: 0.9555555555555556\n",
      "Bagging recall: 0.8657718120805369\n",
      "Bagging f1-score: 0.9084507042253521\n",
      "Bagging confusion matrix: \n",
      "[[960   6]\n",
      " [ 20 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDEs\\anaconda\\envs\\email-ham-spam\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost trained\n",
      "AdaBoost accuracy: 0.9811659192825112\n",
      "AdaBoost precision: 0.9507042253521126\n",
      "AdaBoost recall: 0.9060402684563759\n",
      "AdaBoost f1-score: 0.9278350515463918\n",
      "AdaBoost confusion matrix: \n",
      "[[959   7]\n",
      " [ 14 135]]\n",
      "ExtraTrees trained\n",
      "ExtraTrees accuracy: 0.9820627802690582\n",
      "ExtraTrees precision: 1.0\n",
      "ExtraTrees recall: 0.8657718120805369\n",
      "ExtraTrees f1-score: 0.9280575539568345\n",
      "ExtraTrees confusion matrix: \n",
      "[[966   0]\n",
      " [ 20 129]]\n",
      "GradientBoosting trained\n",
      "GradientBoosting accuracy: 0.9766816143497757\n",
      "GradientBoosting precision: 0.984251968503937\n",
      "GradientBoosting recall: 0.8389261744966443\n",
      "GradientBoosting f1-score: 0.9057971014492754\n",
      "GradientBoosting confusion matrix: \n",
      "[[964   2]\n",
      " [ 24 125]]\n",
      "RandomForest trained\n",
      "RandomForest accuracy: 0.9820627802690582\n",
      "RandomForest precision: 1.0\n",
      "RandomForest recall: 0.8657718120805369\n",
      "RandomForest f1-score: 0.9280575539568345\n",
      "RandomForest confusion matrix: \n",
      "[[966   0]\n",
      " [ 20 129]]\n",
      "MultinomialNB trained\n",
      "MultinomialNB accuracy: 0.9739910313901345\n",
      "MultinomialNB precision: 1.0\n",
      "MultinomialNB recall: 0.8053691275167785\n",
      "MultinomialNB f1-score: 0.8921933085501859\n",
      "MultinomialNB confusion matrix: \n",
      "[[966   0]\n",
      " [ 29 120]]\n",
      "BernoulliNB trained\n",
      "BernoulliNB accuracy: 0.9811659192825112\n",
      "BernoulliNB precision: 0.9637681159420289\n",
      "BernoulliNB recall: 0.8926174496644296\n",
      "BernoulliNB f1-score: 0.926829268292683\n",
      "BernoulliNB confusion matrix: \n",
      "[[961   5]\n",
      " [ 16 133]]\n",
      "MLP trained\n",
      "MLP accuracy: 0.9874439461883409\n",
      "MLP precision: 0.9927007299270073\n",
      "MLP recall: 0.912751677852349\n",
      "MLP f1-score: 0.951048951048951\n",
      "MLP confusion matrix: \n",
      "[[965   1]\n",
      " [ 13 136]]\n",
      "Perceptron trained\n",
      "Perceptron accuracy: 0.97847533632287\n",
      "Perceptron precision: 0.9139072847682119\n",
      "Perceptron recall: 0.9261744966442953\n",
      "Perceptron f1-score: 0.92\n",
      "Perceptron confusion matrix: \n",
      "[[953  13]\n",
      " [ 11 138]]\n",
      "SGD trained\n",
      "SGD accuracy: 0.9874439461883409\n",
      "SGD precision: 1.0\n",
      "SGD recall: 0.9060402684563759\n",
      "SGD f1-score: 0.9507042253521126\n",
      "SGD confusion matrix: \n",
      "[[966   0]\n",
      " [ 14 135]]\n",
      "PassiveAggressiveClassifier trained\n",
      "PassiveAggressiveClassifier accuracy: 0.9901345291479821\n",
      "PassiveAggressiveClassifier precision: 0.9928571428571429\n",
      "PassiveAggressiveClassifier recall: 0.9328859060402684\n",
      "PassiveAggressiveClassifier f1-score: 0.9619377162629758\n",
      "PassiveAggressiveClassifier confusion matrix: \n",
      "[[965   1]\n",
      " [ 10 139]]\n"
     ]
    }
   ],
   "source": [
    "for name,clf in clfs.items():\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    print(f'{name} trained')\n",
    "    ypred=clf.predict(xtest)\n",
    "    print(f'{name} accuracy: {sklearn.metrics.accuracy_score(ytest,ypred)}')\n",
    "    print(f'{name} precision: {precision_score(ytest,ypred)}')\n",
    "    print(f'{name} recall: {recall_score(ytest,ypred)}')\n",
    "    print(f'{name} f1-score: {f1_score(ytest,ypred)}')\n",
    "    print(f'{name} confusion matrix: ')\n",
    "    print(sklearn.metrics.confusion_matrix(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting model\n",
    "We can see that SGDClassifier is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model=pickle.dump(sgd,open('model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email-ham-spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
